#!/usr/bin/env python3
"""
Training Stability Diagnostic Tool

Analyzes why training is jumpy and suggests fixes.
"""

import pandas as pd
import numpy as np
from pathlib import Path
import argparse


def analyze_training_stability(results_csv_path):
    """
    Analyze training stability from results.csv
    """
    results_csv = Path(results_csv_path)
    if not results_csv.exists():
        print(f"‚ùå Error: {results_csv} not found")
        return
    
    df = pd.read_csv(results_csv)
    df.columns = df.columns.str.strip()
    
    print("\n" + "=" * 80)
    print("TRAINING STABILITY ANALYSIS")
    print("=" * 80)
    
    # Key metrics to analyze
    metrics = {
        'metrics/precision(B)': 'Precision',
        'metrics/recall(B)': 'Recall',
        'metrics/mAP50(B)': 'mAP50',
        'val/box_loss': 'Val Box Loss',
        'val/cls_loss': 'Val Cls Loss',
    }
    
    print("\nüìä STABILITY METRICS (Lower = More Stable)\n")
    print(f"{'Metric':<20} {'Std Dev':<12} {'CV (%)':<12} {'Stability':<15}")
    print("-" * 65)
    
    instability_scores = {}
    
    for col, name in metrics.items():
        if col not in df.columns:
            continue
        
        values = df[col].dropna()
        if len(values) < 2:
            continue
        
        # Calculate stability metrics
        mean_val = values.mean()
        std_val = values.std()
        cv = (std_val / mean_val * 100) if mean_val != 0 else float('inf')
        
        # Calculate consecutive differences (jumpiness)
        diffs = values.diff().abs()
        mean_diff = diffs.mean()
        
        # Stability score (lower is better)
        # Penalize: high CV, high consecutive differences
        stability_score = cv * 0.7 + (mean_diff / mean_val * 100) * 0.3 if mean_val != 0 else float('inf')
        instability_scores[name] = stability_score
        
        # Classify stability
        if cv < 5:
            stability = "üü¢ Excellent"
        elif cv < 10:
            stability = "üü° Good"
        elif cv < 20:
            stability = "üü† Moderate"
        else:
            stability = "üî¥ Poor"
        
        print(f"{name:<20} {std_val:>11.4f} {cv:>11.2f} {stability:<15}")
    
    # Overall stability assessment
    print("\n" + "-" * 80)
    avg_instability = np.mean(list(instability_scores.values()))
    
    print(f"\nüéØ OVERALL STABILITY SCORE: {avg_instability:.2f}")
    if avg_instability < 10:
        overall = "üü¢ EXCELLENT - Training is very stable"
    elif avg_instability < 20:
        overall = "üü° GOOD - Training is reasonably stable"
    elif avg_instability < 40:
        overall = "üü† MODERATE - Training shows some instability"
    else:
        overall = "üî¥ POOR - Training is very unstable (JUMPY)"
    
    print(f"   Assessment: {overall}")
    
    # Analyze overfitting
    print("\nüìâ OVERFITTING ANALYSIS\n")
    
    if 'train/box_loss' in df.columns and 'val/box_loss' in df.columns:
        train_loss = df['train/box_loss'].dropna()
        val_loss = df['val/box_loss'].dropna()
        
        if len(train_loss) > 10 and len(val_loss) > 10:
            # Check if validation loss is increasing while training loss decreases
            train_trend = np.polyfit(range(len(train_loss)), train_loss, 1)[0]
            val_trend = np.polyfit(range(len(val_loss)), val_loss, 1)[0]
            
            gap = val_loss.iloc[-1] - train_loss.iloc[-1]
            gap_ratio = gap / train_loss.iloc[-1] * 100
            
            print(f"  Train Loss Trend: {'üìâ Decreasing' if train_trend < 0 else 'üìà Increasing'}")
            print(f"  Val Loss Trend:   {'üìâ Decreasing' if val_trend < 0 else 'üìà Increasing'}")
            print(f"  Final Gap:        {gap:.4f} ({gap_ratio:.1f}%)")
            
            if val_trend > 0 and train_trend < 0:
                print(f"  Status:           üî¥ OVERFITTING DETECTED")
            elif gap_ratio > 50:
                print(f"  Status:           üü† High train-val gap (possible overfitting)")
            else:
                print(f"  Status:           üü¢ No significant overfitting")
    
    # Convergence analysis
    print("\nüìà CONVERGENCE ANALYSIS\n")
    
    if 'metrics/mAP50(B)' in df.columns:
        mAP50 = df['metrics/mAP50(B)'].dropna()
        
        if len(mAP50) > 20:
            # Check last 20 epochs
            last_20 = mAP50.iloc[-20:]
            improvement = last_20.iloc[-1] - last_20.iloc[0]
            
            print(f"  Last 20 epochs improvement: {improvement*100:+.2f}%")
            
            if abs(improvement) < 0.01:
                print(f"  Status: üü° PLATEAU - Model has converged")
            elif improvement > 0.02:
                print(f"  Status: üü¢ IMPROVING - Still learning")
            elif improvement < -0.02:
                print(f"  Status: üî¥ DEGRADING - Model is getting worse")
            else:
                print(f"  Status: üü° SLOW PROGRESS - Near convergence")
    
    # Root cause analysis
    print("\n" + "=" * 80)
    print("üîç ROOT CAUSE ANALYSIS & RECOMMENDATIONS")
    print("=" * 80)
    
    issues = []
    recommendations = []
    
    # Check for high instability
    if avg_instability > 40:
        issues.append("‚ùå Very high training instability (jumpy curves)")
        recommendations.extend([
            "‚úì Increase batch size to 64 or higher",
            "‚úì Reduce learning rate by 5-10x",
            "‚úì Use AdamW optimizer instead of SGD",
            "‚úì Increase warmup epochs to 20+",
        ])
    elif avg_instability > 20:
        issues.append("‚ö†Ô∏è  Moderate training instability")
        recommendations.extend([
            "‚úì Increase batch size to 48-64",
            "‚úì Reduce learning rate by 2-3x",
            "‚úì Consider AdamW optimizer",
        ])
    
    # Check for overfitting
    if 'val/box_loss' in df.columns:
        val_loss = df['val/box_loss'].dropna()
        if len(val_loss) > 10:
            last_10 = val_loss.iloc[-10:]
            if last_10.iloc[-1] > last_10.iloc[0]:
                issues.append("‚ùå Validation loss increasing (overfitting)")
                recommendations.extend([
                    "‚úì Increase dropout (e.g., 0.2-0.3)",
                    "‚úì Increase weight decay",
                    "‚úì Reduce augmentation intensity",
                    "‚úì Use earlier checkpoint (before overfitting)",
                ])
    
    # Check for lack of convergence
    if 'metrics/mAP50(B)' in df.columns:
        mAP50 = df['metrics/mAP50(B)'].dropna()
        if len(mAP50) > 20:
            last_20 = mAP50.iloc[-20:]
            if last_20.std() > 0.05:
                issues.append("‚ö†Ô∏è  High variance in recent epochs")
                recommendations.extend([
                    "‚úì Increase batch size for more stable gradients",
                    "‚úì Reduce learning rate",
                ])
    
    if issues:
        print("\nüî¥ ISSUES DETECTED:\n")
        for issue in issues:
            print(f"  {issue}")
    else:
        print("\nüü¢ NO MAJOR ISSUES DETECTED")
    
    if recommendations:
        print("\nüí° RECOMMENDED FIXES:\n")
        for rec in recommendations:
            print(f"  {rec}")
    
    print("\n" + "=" * 80)


def main():
    parser = argparse.ArgumentParser(description="Analyze training stability")
    parser.add_argument('results_csv', type=str, help='Path to results.csv')
    args = parser.parse_args()
    
    analyze_training_stability(args.results_csv)


if __name__ == '__main__':
    main()
