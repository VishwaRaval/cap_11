# Weights & Biases Integration Guide

## Quick Start

### 1. Install wandb
```bash
pip install wandb
```

### 2. Login to W&B
```bash
# Option A: Login interactively (will cache credentials)
wandb login

# Option B: Set environment variable
export WANDB_API_KEY="your_api_key_here"

# Option C: Use --wandb-key flag when training
python train_yolo11_fish.py --data dataset_root --model n --wandb-key "your_api_key"
```

### 3. Train with W&B
```bash
# Basic training with W&B (default project: underwater-fish-detection)
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 100 \
    --batch 16

# Custom project and run notes
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 100 \
    --batch 16 \
    --wandb-project "my-fish-project" \
    --wandb-notes "Testing enhanced augmentation strategy"

# Train without W&B
python train_yolo11_fish.py \
    --data dataset_root \
    --model n \
    --epochs 100 \
    --batch 16 \
    --no-wandb
```

## What Gets Logged to W&B

### Training Metrics (per epoch)
- **Losses**:
  - `train/box_loss`, `train/cls_loss`, `train/dfl_loss`
  - `val/box_loss`, `val/cls_loss`, `val/dfl_loss`

- **Performance Metrics**:
  - `precision`: Precision at confidence threshold
  - `recall`: Recall at confidence threshold
  - `mAP50`: Mean Average Precision at IoU 0.5
  - `mAP50-95`: Mean Average Precision at IoU 0.5-0.95

### Visualizations
- Training curves (losses, mAP, precision/recall)
- Confusion matrix
- Prediction examples
- All plots generated by Ultralytics

### Model Artifacts
- Best model weights (`best.pt`)
- Automatically versioned and stored in W&B

### Configuration
All hyperparameters and settings are logged:
- Model size (n/s/m)
- Training parameters (epochs, batch size, image size)
- Dataset path
- Optimizer settings
- Custom tags for organization

## W&B Dashboard Features

### Real-time Monitoring
- Live training curves as your model trains
- Compare multiple runs side-by-side
- Track GPU utilization and system metrics

### Experiment Organization
- All runs automatically tagged with:
  - `yolov11`
  - `underwater`
  - `fish-detection`
  - `edge-deployment`
  - Model size (e.g., `n`, `s`)

### Hyperparameter Comparison
- Compare different model sizes (nano vs small)
- Test augmentation strategies
- Evaluate preprocessing effects
- Track recall optimization experiments

## Example Training Commands with W&B

### Baseline Experiment
```bash
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 100 \
    --batch 16 \
    --name baseline \
    --wandb-notes "Baseline with preprocessed dataset"
```

### Enhanced Augmentation
```bash
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 120 \
    --batch 16 \
    --name enhanced_aug \
    --wandb-notes "Testing stronger augmentation for recall improvement"
```

### Compare Model Sizes
```bash
# Nano model
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 100 \
    --batch 16 \
    --name size_comparison

# Small model
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model s \
    --epochs 100 \
    --batch 8 \
    --name size_comparison
```

### Transfer Learning
```bash
python train_yolo11_fish.py \
    --data dataset_root_preprocessed \
    --model n \
    --epochs 50 \
    --batch 16 \
    --weights path/to/roboflow_checkpoint.pt \
    --name transfer \
    --wandb-notes "Transfer learning from Roboflow checkpoint"
```

## Environment Variables

You can configure W&B behavior with environment variables:

```bash
# API Key (instead of interactive login)
export WANDB_API_KEY="your_api_key"

# Run in offline mode (sync later with: wandb sync)
export WANDB_MODE=offline

# Disable W&B completely
export WANDB_MODE=disabled

# Custom W&B directory
export WANDB_DIR="/path/to/wandb"

# Silent mode (less verbose output)
export WANDB_SILENT=true
```

## Comparing Experiments in W&B

### View Multiple Runs
1. Go to your W&B project dashboard
2. Select multiple runs using checkboxes
3. Click "Compare" to see side-by-side metrics

### Filter and Group
- Filter runs by tags: `yolov11`, `nano`, `edge-deployment`
- Group runs by model size or dataset
- Create custom views for specific experiments

### Export Data
- Download metrics as CSV for custom analysis
- Export model weights from artifacts
- Generate reports to share results

## Troubleshooting

### W&B not logging?
```bash
# Check if wandb is installed
pip show wandb

# Test login
wandb login

# Verify API key
echo $WANDB_API_KEY
```

### Run failed but want to log partial results?
```bash
# W&B automatically saves progress
# Check your dashboard for the incomplete run
# Metrics logged before failure are preserved
```

### Too many runs cluttering dashboard?
- Archive old runs in W&B UI
- Delete test runs
- Use meaningful names and tags for organization

## Best Practices

1. **Use descriptive run names**: 
   ```bash
   --name baseline_v1
   --name enhanced_aug_v2
   ```

2. **Add notes for context**:
   ```bash
   --wandb-notes "Testing recall optimization with hsv_s=0.6"
   ```

3. **Tag experiments systematically**:
   - Runs are auto-tagged with model size and task
   - Add custom tags in W&B UI for further organization

4. **Compare related experiments**:
   - Use same project for related runs
   - Compare metrics side-by-side in W&B dashboard

5. **Save important runs**:
   - Star best performing runs in W&B
   - Add notes about why they performed well

## Integration with Experiment Plan

The W&B integration perfectly supports your experiment plan:

### Phase 1: Baseline
```bash
python train_yolo11_fish.py --data dataset_root_preprocessed --model n --epochs 100 --batch 16 --name baseline
```
**W&B will track**: Initial metrics, establish performance baseline

### Phase 2: Optimization
```bash
python train_yolo11_fish.py --data dataset_root_preprocessed --model n --epochs 120 --batch 16 --name enhanced_aug
```
**W&B will track**: Recall improvements, augmentation effects

### Phase 3: Advanced Experiments
```bash
# Compare preprocessing
python train_yolo11_fish.py --data dataset_root --model n --epochs 100 --batch 16 --name no_preprocess

# Compare model sizes
python train_yolo11_fish.py --data dataset_root_preprocessed --model s --epochs 100 --batch 8 --name yolo11s
```
**W&B will track**: All comparisons in one dashboard

## Access Your Runs

After training starts, you'll see output like:
```
‚úì W&B initialized: fish_n_baseline
  Project: underwater-fish-detection
  URL: https://wandb.ai/your-username/underwater-fish-detection/runs/xxx
```

Click the URL to view your run in real-time!

---

**Happy training! üê†üìä**
